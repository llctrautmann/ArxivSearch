{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import os\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "import arxiv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "API_KEY = os.getenv('APP_TOKEN')\n",
    "USER_KEY = os.getenv('USER_TOKEN')\n",
    "HOME_PATH = os.getenv('HOME_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/luca/Desktop/Cache/ArvixSearch/Relevance.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(HOME_PATH, \"Relevance.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - Add error handling\n",
    "# - Add logging\n",
    "# - Add search term optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186760.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "\n",
    "def find_last_hyperlink_end(s: str, limit: int = 1024) -> int:\n",
    "    \"\"\"\n",
    "    Find the end index of the last hyperlink within the first `limit` characters of a string.\n",
    "\n",
    "    Parameters:\n",
    "    - s (str): The input string.\n",
    "    - limit (int): The maximum number of characters to search within, default is 1024.\n",
    "\n",
    "    Returns:\n",
    "    - int: The end index of the last hyperlink found within the limit, or -1 if none found.\n",
    "    \"\"\"\n",
    "    # Adjust the limit if it's beyond the string's length\n",
    "    limit = min(limit, len(s))\n",
    "\n",
    "    # Regular expression to find hyperlinks\n",
    "    pattern = r'https?://[^\\s]+'\n",
    "\n",
    "    # Find all hyperlinks within the limit\n",
    "    matches = [match for match in re.finditer(pattern, s[:limit])]\n",
    "\n",
    "    if matches:\n",
    "        # Return the end index of the last match\n",
    "        return matches[-1].end()\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def split_text_by_hyperlinks(s: str) -> list:\n",
    "    \"\"\"\n",
    "    Split the text into parts based on hyperlinks, where each part ends with a hyperlink\n",
    "    and is up to 1024 characters long.\n",
    "\n",
    "    Parameters:\n",
    "    - s (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of string parts, each ending with a hyperlink and up to 1024 characters long.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    while len(s) > 1024:\n",
    "        end_index = find_last_hyperlink_end(s, 1024)\n",
    "        if end_index == -1:  # No hyperlink found within 1024 characters\n",
    "            # Split at 1024 if no hyperlink is found\n",
    "            parts.append(s[:1024])\n",
    "            s = s[1024:]\n",
    "        else:\n",
    "            # Include the hyperlink in the current part\n",
    "            parts.append(s[:end_index])\n",
    "            # Start the next part after the hyperlink\n",
    "            s = s[end_index:]\n",
    "    parts.append(s)  # Add the remaining part of the string\n",
    "    return parts\n",
    "\n",
    "def remove_known_entries(data: dict, existing_titles: list):\n",
    "    \"\"\"\n",
    "    Remove entries from the data dictionary whose titles exist in the existing_titles list.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): A dictionary of data entries.\n",
    "    - existing_titles (list): A list of titles to be removed from the data.\n",
    "    \"\"\"\n",
    "    for key in list(data.keys()):\n",
    "        if data[key]['title'] in existing_titles:\n",
    "            del data[key]\n",
    "\n",
    "\n",
    "def extract_information(data, key=\"title\"):\n",
    "    \"\"\"\n",
    "    Extract information based on a specified key from each entry in the data dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): A dictionary of data entries.\n",
    "    - key (str): The key to extract information from each entry. Defaults to \"title\".\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of extracted information from each data entry.\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    for i in list(data.keys()):\n",
    "        output = data[i][key]\n",
    "        titles.append(output)\n",
    "    return titles\n",
    "\n",
    "\n",
    "def turn_into_tuples(data: dict) -> list:\n",
    "    \"\"\"\n",
    "    Convert the data dictionary into a list of tuples containing specified information.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): A dictionary of data entries.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of tuples, each containing the 'title' and 'entry_id' of an entry.\n",
    "    \"\"\"\n",
    "    return [(v['title'], v['entry_id']) for v in data.values()]\n",
    "\n",
    "\n",
    "def read_list_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a list of strings from a specified file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the file to be read.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of strings read from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content.split('\\n')[:-1]\n",
    "\n",
    "\n",
    "def append_titles_to_file(new_titles, file_path):\n",
    "    \"\"\"\n",
    "    Append new titles to an existing file.\n",
    "\n",
    "    Parameters:\n",
    "    - new_titles (list): A list of new titles to append.\n",
    "    - file_path (str): The path to the file where titles will be appended.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'a') as file:\n",
    "        # Ensure there's a newline at the start to separate from existing content\n",
    "        file.write('\\n'.join(new_titles) + '\\n')\n",
    "\n",
    "\n",
    "def search_arvix(field=\"cs.cv\", title_keyword=\"low field MRI\"):\n",
    "    \"\"\"\n",
    "    Search the arXiv for papers matching a specific field and title keyword.\n",
    "\n",
    "    Parameters:\n",
    "    - field (str): The field to search within. Defaults to \"cs.cv\".\n",
    "    - title_keyword (str): The keyword to search in titles. Defaults to \"low field MRI\".\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Two dictionaries containing search results sorted by SubmittedDate and Relevance.\n",
    "    \"\"\"\n",
    "    client = arxiv.Client()\n",
    "    # TODO: Add multifield search for fields\n",
    "\n",
    "    if type(field) is list:\n",
    "        field = \" OR cat:\".join(field)\n",
    "\n",
    "    # initialise searches for both SubmittedDate and Relevance\n",
    "    sort_criteria = [arxiv.SortCriterion.SubmittedDate, arxiv.SortCriterion.Relevance]\n",
    "    results = {}\n",
    "\n",
    "    for criterion in sort_criteria:\n",
    "        search = arxiv.Search(\n",
    "            query=f\"cat:{field} AND ti:{title_keyword}\",\n",
    "            max_results=50 if criterion == arxiv.SortCriterion.Relevance else 30,\n",
    "            sort_by=criterion\n",
    "        )\n",
    "        results[criterion] = {idx: {\"title\": r.title, \"entry_id\": r.entry_id} for idx, r in enumerate(client.results(search))}\n",
    "\n",
    "    submitted_date_titles = results[arxiv.SortCriterion.SubmittedDate]\n",
    "    relevance_titles = results[arxiv.SortCriterion.Relevance]\n",
    "\n",
    "    return relevance_titles, submitted_date_titles\n",
    "\n",
    "\n",
    "def join_tuples(tuples_list):\n",
    "    \"\"\"\n",
    "    Join a list of tuples into a single string, with each tuple converted to a string and separated by a newline.\n",
    "\n",
    "    Parameters:\n",
    "    - tuples_list (list): A list of tuples to be joined.\n",
    "\n",
    "    Returns:\n",
    "    - str: A single string representation of the list of tuples.\n",
    "    \"\"\"\n",
    "    # Convert each tuple to a string by joining each element with a space\n",
    "    tuples_str = [\" \".join(map(str, t)) for t in tuples_list]\n",
    "    # Join the list of strings with \"\\n\" to get a single string\n",
    "    result = \"\\n\".join(tuples_str)\n",
    "    return result\n",
    "\n",
    "\n",
    "def push_to_device(api_key, user_key, message, header):\n",
    "    \"\"\"\n",
    "    Push a message to a device using the Pushover API.\n",
    "\n",
    "    Parameters:\n",
    "    - api_key (str): The API key for authentication.\n",
    "    - user_key (str): The user key for the target device.\n",
    "    - message (str): The message to be sent.\n",
    "    - header (str): A descriptor for the message, e.g., \"Relevance\" or \"SubmittedDate\".\n",
    "    \"\"\"\n",
    "    conn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n",
    "    conn.request(\"POST\", \"/1/messages.json\",\n",
    "        urllib.parse.urlencode({\n",
    "        \"token\": api_key,\n",
    "        \"user\": user_key,\n",
    "        \"title\": f\"Daily Paper Dump | {header}\",\n",
    "        \"message\": message,\n",
    "        \"sound\": \"vibrate\",\n",
    "        }), {\"Content-type\": \"application/x-www-form-urlencoded\"})\n",
    "    conn.getresponse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(field, title_keyword):\n",
    "    \"\"\"\n",
    "    Main function to process new papers from arXiv based on predefined criteria.\n",
    "\n",
    "    This function performs several steps:\n",
    "    1. Reads the current status of papers (titles) from files for relevance and submitted date.\n",
    "    2. Calls the arXiv API to search for new papers based on predefined search criteria.\n",
    "    3. Removes known entries from the new papers fetched to avoid duplicates.\n",
    "    4. Extracts titles from the new papers and appends them to the respective files.\n",
    "    5. Pushes notifications about the new papers to a device using the Pushover API.\n",
    "    \"\"\"\n",
    "    current_status_relevance = read_list_from_file(\"Relevance.txt\") # list of strings\n",
    "    current_status_submitted_date = read_list_from_file(\"SubmittedDate.txt\") # list of strings\n",
    "\n",
    "    current_status = [current_status_relevance, current_status_submitted_date]\n",
    "    headers = [\"Relevance\", \"SubmittedDate\"]\n",
    "\n",
    "    # Call API for new paper\n",
    "    queries = search_arvix(field, title_keyword)\n",
    "\n",
    "    for idx, query in enumerate(queries):\n",
    "        remove_known_entries(query, current_status[idx])\n",
    "        new_relevance_titles = extract_information(query)\n",
    "        # append_titles_to_file(new_relevance_titles, f\"{headers[idx]}.txt\")\n",
    "\n",
    "        payload = join_tuples(turn_into_tuples(query))\n",
    "\n",
    "        if len(new_relevance_titles) > 0:\n",
    "            parts = [part.lstrip() for part in split_text_by_hyperlinks(payload)][::-1]\n",
    "\n",
    "            for idy, part in enumerate(parts):\n",
    "                if len(parts) > 1:\n",
    "                    push_to_device(API_KEY, USER_KEY, part, f\"{headers[idx]} | Part {-idy + len(parts)}\")\n",
    "                else:\n",
    "                    push_to_device(API_KEY, USER_KEY, part, f\"{headers[idx]}\")\n",
    "        else:\n",
    "            push_to_device(API_KEY, USER_KEY, \"No new papers\", f\"{headers[idx]}\")\n",
    "\n",
    "main(field=\"cs.cv\", title_keyword=\"mambaMIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: {'title': 'Denoising Simulated Low-Field MRI (70mT) using Denoising Autoencoders (DAE) and Cycle-Consistent Generative Adversarial Networks (Cycle-GAN)',\n",
       "   'entry_id': 'http://arxiv.org/abs/2307.06338v1'},\n",
       "  1: {'title': 'Low-field magnetic resonance image enhancement via stochastic image quality transfer',\n",
       "   'entry_id': 'http://arxiv.org/abs/2304.13385v1'},\n",
       "  2: {'title': 'Accurate super-resolution low-field brain MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2202.03564v1'},\n",
       "  3: {'title': 'Synthetic Low-Field MRI Super-Resolution Via Nested U-Net Architecture',\n",
       "   'entry_id': 'http://arxiv.org/abs/2211.15047v1'},\n",
       "  4: {'title': 'External Dynamic InTerference Estimation and Removal (EDITER) for low field MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2104.08680v2'},\n",
       "  5: {'title': 'Quantifying white matter hyperintensity and brain volumes in heterogeneous clinical and low-field portable MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.05119v2'},\n",
       "  6: {'title': 'An automated pipeline for quantitative T2* fetal body MRI and segmentation at low field',\n",
       "   'entry_id': 'http://arxiv.org/abs/2308.04903v1'},\n",
       "  7: {'title': 'Faithful Synthesis of Low-dose Contrast-enhanced Brain MRI Scans using Noise-preserving Conditional GANs',\n",
       "   'entry_id': 'http://arxiv.org/abs/2306.14678v1'},\n",
       "  8: {'title': 'Simultaneous imaging of hard and soft biological tissues in a low-field dental MRI scanner',\n",
       "   'entry_id': 'http://arxiv.org/abs/2005.01462v1'},\n",
       "  9: {'title': 'Evaluating the Performance of Ultra-Low-Field MRI for In-vivo 3D Current Density Imaging of the Human Head',\n",
       "   'entry_id': 'http://arxiv.org/abs/2001.07178v1'},\n",
       "  10: {'title': 'A 3D Conditional Diffusion Model for Image Quality Transfer -- An Application to Low-Field MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2311.06631v1'},\n",
       "  11: {'title': 'Learning Deep MRI Reconstruction Models from Scratch in Low-Data Regimes',\n",
       "   'entry_id': 'http://arxiv.org/abs/2301.02613v1'},\n",
       "  12: {'title': 'Improving the Segmentation of Pediatric Low-Grade Gliomas through Multitask Learning',\n",
       "   'entry_id': 'http://arxiv.org/abs/2111.14959v1'},\n",
       "  13: {'title': 'Image Quality Transfer Enhances Contrast and Resolution of Low-Field Brain MRI in African Paediatric Epilepsy Patients',\n",
       "   'entry_id': 'http://arxiv.org/abs/2003.07216v2'},\n",
       "  14: {'title': 'Dynamic MRI reconstruction using low-rank plus sparse decomposition with smoothness regularization',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.16928v1'},\n",
       "  15: {'title': 'Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images',\n",
       "   'entry_id': 'http://arxiv.org/abs/2311.07348v1'},\n",
       "  16: {'title': 'SuperMask: Generating High-resolution object masks from multi-view, unaligned low-resolution MRIs',\n",
       "   'entry_id': 'http://arxiv.org/abs/2303.07517v1'},\n",
       "  17: {'title': 'One-dimensional Deep Low-rank and Sparse Network for Accelerated MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2112.04721v1'},\n",
       "  18: {'title': 'Brain MRI study for glioma segmentation using convolutional neural networks and original post-processing techniques with low computational demand',\n",
       "   'entry_id': 'http://arxiv.org/abs/2207.07622v1'},\n",
       "  19: {'title': 'Benchmarking the performance of a low-cost Magnetic Resonance Control System at multiple sites in the open MaRCoS community',\n",
       "   'entry_id': 'http://arxiv.org/abs/2203.11314v2'},\n",
       "  20: {'title': 'Distribution-based Low-rank Embedding',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.17579v1'},\n",
       "  21: {'title': 'Deep Learning for Low-Field to High-Field MR: Image Quality Transfer with Probabilistic Decimation Simulator',\n",
       "   'entry_id': 'http://arxiv.org/abs/1909.06763v1'},\n",
       "  22: {'title': 'Deep Low-rank plus Sparse Network for Dynamic MR Imaging',\n",
       "   'entry_id': 'http://arxiv.org/abs/2010.13677v3'},\n",
       "  23: {'title': 'Self-Learned Kernel Low Rank Approach TO Accelerated High Resolution 3D Diffusion MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2110.08622v3'},\n",
       "  24: {'title': 'Motion Compensated Extreme MRI: Multi-Scale Low Rank Reconstructions for Highly Accelerated 3D Dynamic Acquisitions (MoCo-MSLR)',\n",
       "   'entry_id': 'http://arxiv.org/abs/2205.00131v1'},\n",
       "  25: {'title': 'LoMAE: Low-level Vision Masked Autoencoders for Low-dose CT Denoising',\n",
       "   'entry_id': 'http://arxiv.org/abs/2310.12405v1'},\n",
       "  26: {'title': 'Masked Co-attentional Transformer reconstructs 100x ultra-fast/low-dose whole-body PET from longitudinal images and anatomically guided MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2205.04044v1'},\n",
       "  27: {'title': 'Unsupervised Hyperspectral Pansharpening via Low-rank Diffusion Model',\n",
       "   'entry_id': 'http://arxiv.org/abs/2305.10925v2'},\n",
       "  28: {'title': 'Low-latency Perception in Off-Road Dynamical Low Visibility Environments',\n",
       "   'entry_id': 'http://arxiv.org/abs/2012.13014v1'},\n",
       "  29: {'title': 'Low-Dose CT Denoising via Sinogram Inner-Structure Transformer',\n",
       "   'entry_id': 'http://arxiv.org/abs/2204.03163v2'},\n",
       "  30: {'title': 'Probabilistic self-learning framework for Low-dose CT Denoising',\n",
       "   'entry_id': 'http://arxiv.org/abs/2006.00327v2'},\n",
       "  31: {'title': 'SkinScan: Low-Cost 3D-Scanning for Dermatologic Diagnosis and Documentation',\n",
       "   'entry_id': 'http://arxiv.org/abs/2102.00508v1'},\n",
       "  32: {'title': 'Ensembling Low Precision Models for Binary Biomedical Image Segmentation',\n",
       "   'entry_id': 'http://arxiv.org/abs/2010.08648v1'},\n",
       "  33: {'title': 'DEANet: Decomposition Enhancement and Adjustment Network for Low-Light Image Enhancement',\n",
       "   'entry_id': 'http://arxiv.org/abs/2209.06823v1'},\n",
       "  34: {'title': 'DPFNet: A Dual-branch Dilated Network with Phase-aware Fourier Convolution for Low-light Image Enhancement',\n",
       "   'entry_id': 'http://arxiv.org/abs/2209.07937v1'},\n",
       "  35: {'title': 'LRT: An Efficient Low-Light Restoration Transformer for Dark Light Field Images',\n",
       "   'entry_id': 'http://arxiv.org/abs/2209.02197v2'},\n",
       "  36: {'title': 'Pano-NeRF: Synthesizing High Dynamic Range Novel Views with Geometry from Sparse Low Dynamic Range Panoramic Images',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.15942v2'},\n",
       "  37: {'title': 'Fast Low Rank column-wise Compressive Sensing for Accelerated Dynamic MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2206.13618v2'},\n",
       "  38: {'title': 'Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network',\n",
       "   'entry_id': 'http://arxiv.org/abs/2308.05404v2'},\n",
       "  39: {'title': 'Harnessing Multi-View Perspective of Light Fields for Low-Light Imaging',\n",
       "   'entry_id': 'http://arxiv.org/abs/2003.02438v2'},\n",
       "  40: {'title': 'Deep Low-rank Prior in Dynamic MR Imaging',\n",
       "   'entry_id': 'http://arxiv.org/abs/2006.12090v4'},\n",
       "  41: {'title': 'Masked Autoencoders for Low dose CT denoising',\n",
       "   'entry_id': 'http://arxiv.org/abs/2210.04944v1'},\n",
       "  42: {'title': 'SHISRCNet: Super-resolution And Classification Network For Low-resolution Breast Cancer Histopathology Image',\n",
       "   'entry_id': 'http://arxiv.org/abs/2306.14119v1'},\n",
       "  43: {'title': 'EDCNN: Edge enhancement-based Densely Connected Network with Compound Loss for Low-Dose CT Denoising',\n",
       "   'entry_id': 'http://arxiv.org/abs/2011.00139v1'},\n",
       "  44: {'title': 'Hyperspectral Image Denoising and Anomaly Detection Based on Low-rank and Sparse Representations',\n",
       "   'entry_id': 'http://arxiv.org/abs/2103.07437v1'},\n",
       "  45: {'title': 'Estimating temperatures with low-cost infrared cameras using deep neural networks',\n",
       "   'entry_id': 'http://arxiv.org/abs/2307.12130v2'},\n",
       "  46: {'title': 'Wavelet-based Topological Loss for Low-Light Image Denoising',\n",
       "   'entry_id': 'http://arxiv.org/abs/2309.08975v2'},\n",
       "  47: {'title': 'GSR-Net: Graph Super-Resolution Network for Predicting High-Resolution from Low-Resolution Functional Brain Connectomes',\n",
       "   'entry_id': 'http://arxiv.org/abs/2009.11080v1'},\n",
       "  48: {'title': 'Segmentation of Retinal Low-Cost Optical Coherence Tomography Images using Deep Learning',\n",
       "   'entry_id': 'http://arxiv.org/abs/2001.08480v1'},\n",
       "  49: {'title': 'Fast Low Rank column-wise Compressive Sensing for Accelerated Dynamic MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2212.09664v1'}},\n",
       " {0: {'title': 'Low-Res Leads the Way: Improving Generalization for Super-Resolution by Self-Supervised Learning',\n",
       "   'entry_id': 'http://arxiv.org/abs/2403.02601v1'},\n",
       "  1: {'title': 'A Spatio-temporal Aligned SUNet Model for Low-light Video Enhancement',\n",
       "   'entry_id': 'http://arxiv.org/abs/2403.02408v1'},\n",
       "  2: {'title': 'LoLiSRFlow: Joint Single Image Low-light Enhancement and Super-resolution via Cross-scale Transformer-based Conditional Flow',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.18871v1'},\n",
       "  3: {'title': 'A Lightweight Low-Light Image Enhancement Network via Channel Prior and Gamma Correction',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.18147v1'},\n",
       "  4: {'title': 'MISC: Ultra-low Bitrate Image Semantic Compression Driven by Large Multimodal Model',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.16749v2'},\n",
       "  5: {'title': 'Low-Rank Representations Meets Deep Unfolding: A Generalized and Interpretable Network for Hyperspectral Anomaly Detection',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.15335v1'},\n",
       "  6: {'title': 'Advancing Low-Rank and Local Low-Rank Matrix Approximation in Medical Imaging: A Systematic Literature Review and Future Directions',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.14045v1'},\n",
       "  7: {'title': 'Evaluating Adversarial Robustness of Low dose CT Recovery',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.11557v1'},\n",
       "  8: {'title': 'Low-Dose CT Reconstruction Using Dataset-free Learning',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.11186v1'},\n",
       "  9: {'title': 'Poisson flow consistency models for low-dose CT image denoising',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.08159v1'},\n",
       "  10: {'title': 'Spiking Neural Network Enhanced Hand Gesture Recognition Using Low-Cost Single-photon Avalanche Diode Array',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.05441v1'},\n",
       "  11: {'title': 'RAGE for the Machine: Image Compression with Low-Cost Random Access for Embedded Applications',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.05974v1'},\n",
       "  12: {'title': 'Troublemaker Learning for Low-Light Image Enhancement',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.04584v2'},\n",
       "  13: {'title': 'Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype Identification Using a Novel AUROC Loss Function for Convolutional Neural Networks',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.03547v1'},\n",
       "  14: {'title': 'Dynamic MRI reconstruction using low-rank plus sparse decomposition with smoothness regularization',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.16928v1'},\n",
       "  15: {'title': 'Low-resolution Prior Equilibrium Network for CT Reconstruction',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.15663v1'},\n",
       "  16: {'title': 'LYT-Net: Lightweight YUV Transformer-based Network for Low-Light Image Enhancement',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.15204v3'},\n",
       "  17: {'title': 'POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.14285v1'},\n",
       "  18: {'title': 'Self-navigated 3D diffusion MRI using an optimized CAIPI sampling and structured low-rank reconstruction',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.05844v1'},\n",
       "  19: {'title': 'Adaptive Regularized Low-Rank Tensor Decomposition for Hyperspectral Image Denoising and Destriping',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.05682v1'},\n",
       "  20: {'title': 'Cool-Chic: Perceptually Tuned Low Complexity Overfitted Image Coder',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.02156v1'},\n",
       "  21: {'title': 'Shrinking Your TimeStep: Towards Low-Latency Neuromorphic Object Recognition with Spiking Neural Network',\n",
       "   'entry_id': 'http://arxiv.org/abs/2401.01912v1'},\n",
       "  22: {'title': 'Distribution-based Low-rank Embedding',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.17579v1'},\n",
       "  23: {'title': 'Pano-NeRF: Synthesizing High Dynamic Range Novel Views with Geometry from Sparse Low Dynamic Range Panoramic Images',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.15942v2'},\n",
       "  24: {'title': 'Revealing Shadows: Low-Light Image Enhancement Using Self-Calibrated Illumination',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.15199v1'},\n",
       "  25: {'title': 'A Comprehensive End-to-End Computer Vision Framework for Restoration and Recognition of Low-Quality Engineering Drawings',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.13620v1'},\n",
       "  26: {'title': 'Rotational Augmented Noise2Inverse for Low-dose Computed Tomography Reconstruction',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.12644v1'},\n",
       "  27: {'title': 'DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images',\n",
       "   'entry_id': 'http://arxiv.org/abs/2402.18575v1'},\n",
       "  28: {'title': 'Quantifying white matter hyperintensity and brain volumes in heterogeneous clinical and low-field portable MRI',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.05119v2'},\n",
       "  29: {'title': 'C3: High-performance and low-complexity neural compression from a single image or video',\n",
       "   'entry_id': 'http://arxiv.org/abs/2312.02753v1'}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_arvix(\"cs.cv OR cat:eess.iv\", \"low field MRI OR all:low field MRI OR ti:low field magnetic resonance imaging\") # search for low field MRI in computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (math)",
   "language": "python",
   "name": "math"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
